{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pylab as pl\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import clone\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, validation_curve, learning_curve\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "n_classes = 3\n",
    "plot_colors = \"rmb\"\n",
    "plot_step = 0.005\n",
    "#pl.set_cmap(pl.cm.Paired)\n",
    "pl.set_cmap(pl.cm.summer)\n",
    "\n",
    "# Load data\n",
    "iris = load_iris()\n",
    "\n",
    "model = DecisionTreeClassifier()\n",
    "         # We only take the two corresponding features\n",
    "X = iris.data[:, [0,2]]\n",
    "y = iris.target\n",
    "\n",
    "        # Shuffle\n",
    "idx = np.arange(X.shape[0])\n",
    "np.random.seed(13)\n",
    "np.random.shuffle(idx)\n",
    "X = X[idx]\n",
    "y = y[idx]\n",
    "\n",
    "        # Standardize\n",
    "mean = X.mean(axis=0)\n",
    "std = X.std(axis=0)\n",
    "X = (X - mean) / std\n",
    "\n",
    "        # Train\n",
    "clf = clone(model)\n",
    "clf = model.fit(X, y)\n",
    "\n",
    "        # Plot the decision boundary\n",
    "pl.plot()\n",
    "\n",
    "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, plot_step), np.arange(y_min, y_max, plot_step))\n",
    "\n",
    "Z = model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "cs = pl.contourf(xx, yy, Z)\n",
    "    \n",
    "        #pl.xlabel(\"%s / %s\" % (iris.feature_names[pair[0]],\n",
    "        #                       model.__class__.__name__))\n",
    "        #pl.ylabel(iris.feature_names[pair[1]])\n",
    "pl.axis(\"tight\")\n",
    "\n",
    "        # Plot the training points\n",
    "for i, c in zip(range(n_classes), plot_colors):\n",
    "    idx = np.where(y == i)\n",
    "    pl.scatter(X[idx, 0], X[idx, 1], c=c, label=iris.target_names[i])\n",
    "\n",
    "pl.axis(\"tight\")\n",
    "\n",
    "pl.suptitle(\"Decision surface of a decision tree\")\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forest Cover Type Dataset\n",
    "This dataset includes information on trees. More specifically, the type (which is the label to predict), shadow coverage, distance to nearby landmarks (e.g., roads), soil type, and local topography. There are 7 classes of tree types, 55 features, and a total of 15120 data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = pd.read_csv('../Datasets/forest-cover-type.csv')\n",
    "forest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then create two `ndarrays` $X$ and $y$ containing data points and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = forest.drop(columns=['Id', 'Cover_Type']).values\n",
    "y = forest['Cover_Type'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(y, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The class distribution is perfectly balanced.\n",
    "\n",
    "We also create a train-test split with proportions $2/3-1/3$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we evaluate a tree classifier algorithm on this split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner = DecisionTreeClassifier(criterion='gini')\n",
    "\n",
    "learner.fit(X_train, y_train)\n",
    "y_pred = learner.predict(X_test)\n",
    "test_score = accuracy_score(y_test,y_pred)\n",
    "np.round(test_score, decimals=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting tree classifier is quite large and deep."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int(learner.tree_.node_count), int(learner.tree_.max_depth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We compute the CV estimate of the risk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(learner, X, y, cv=5)\n",
    "np.round(scores.mean(), decimals=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we look at the learning curve from 1K to 9K examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sizes = range(1000, 10001, 2000)\n",
    "train_size, train_score, val_score = learning_curve(learner, X, y, train_sizes=sizes, cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.title('Decision tree')\n",
    "train_score_mean = np.mean(train_score, axis=1)\n",
    "train_score_std = np.std(train_score, axis=1)\n",
    "val_score_mean = np.mean(val_score, axis=1)\n",
    "val_score_std = np.std(val_score, axis=1)\n",
    "plt.grid()\n",
    "plt.fill_between(train_size, train_score_mean - train_score_std,\n",
    "                 train_score_mean + train_score_std, alpha=0.1,\n",
    "                 color=\"r\")\n",
    "plt.fill_between(train_size, val_score_mean - val_score_std,\n",
    "                 val_score_mean + val_score_std, alpha=0.1, color=\"g\")\n",
    "plt.plot(train_size, train_score_mean, 'o-', color=\"r\",\n",
    "         label=\"Training accuracy\")\n",
    "plt.plot(train_size, val_score_mean, 'o-', color=\"g\",\n",
    "         label=\"CV accuracy\")\n",
    "plt.legend()\n",
    "plt.xlabel('Training size')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zero training error indicates that the algorithm has no bias, while the large difference between training and test performance reveals a high variance. The final cross-validated performance is only $66\\%$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(np.round(np.mean(val_score, 1), decimals=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what happens when we constrain the depth of the tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depths = np.arange(1,33,5)\n",
    "learner = DecisionTreeClassifier()\n",
    "train_score, val_score = validation_curve(learner, X, y, param_name='max_depth', param_range=depths, cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Tree classifier vs. depth')\n",
    "plt.plot(depths, np.mean(val_score, 1), label='CV accuracy')\n",
    "plt.plot(depths, np.mean(train_score, 1), label='Training accuracy')\n",
    "plt.legend()\n",
    "plt.xlabel('Depth')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below depth 5 the tree underfits. Then overfitting starts. However, the CV estimate of the accuracy does not get any worse."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST dataset\n",
    "Handwritten numerals. The original dataset is already split in training (60K) and test (10K) sets. For efficiency reasons, we only work with the test set, which we further split in training and test.\n",
    "\n",
    "Each row of the data matrix consists of 785 values: the first value is the label (a number from 0 to 9) and the remaining 784 values are the pixel values (a number from 0 to 255)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = pd.read_csv(\"../Datasets/MNIST/mnist_test.csv\")\n",
    "mnist.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create the data matrix, the list of labels, and a train/test split with proportions $4/5-1/5$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_X = mnist.drop(\"label\",1)\n",
    "mnist_y = mnist[\"label\"]\n",
    "X = mnist_X.values\n",
    "y = mnist_y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(y, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, it is instructive to visualize the original images from the list of pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,6))\n",
    "for digit_num in range(0,64):\n",
    "    plt.subplot(8,8,digit_num+1)\n",
    "    grid_data = mnist_X.iloc[digit_num].values.reshape(28,28)\n",
    "    plt.imshow(grid_data, interpolation = \"none\", cmap = \"bone_r\")\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by checking the performance of the standard tree classifier algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_lrn = DecisionTreeClassifier(criterion='gini')\n",
    "\n",
    "tree_lrn.fit(X_train, y_train)\n",
    "y_pred = tree_lrn.predict(X_test)\n",
    "test_score = accuracy_score(y_test,y_pred)\n",
    "np.round(test_score, decimals=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int(tree_lrn.tree_.node_count), int(tree_lrn.tree_.max_depth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The analysis of the learning curve for the tree classifier algorithm shows essentially no bias and a large variance (see below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sizes = range(1000, 6666, 1000)\n",
    "train_size, train_score, val_score = learning_curve(tree_lrn, X, y, train_sizes=sizes, cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.title('Decision tree')\n",
    "train_score_mean = np.mean(train_score, axis=1)\n",
    "train_score_std = np.std(train_score, axis=1)\n",
    "val_score_mean = np.mean(val_score, axis=1)\n",
    "val_score_std = np.std(val_score, axis=1)\n",
    "plt.grid()\n",
    "plt.fill_between(train_size, train_score_mean - train_score_std,\n",
    "                 train_score_mean + train_score_std, alpha=0.1,\n",
    "                 color=\"r\")\n",
    "plt.fill_between(train_size, val_score_mean - val_score_std,\n",
    "                 val_score_mean + val_score_std, alpha=0.1, color=\"g\")\n",
    "plt.plot(train_size, train_score_mean, 'o-', color=\"r\",\n",
    "         label=\"Training score\")\n",
    "plt.plot(train_size, val_score_mean, 'o-', color=\"g\",\n",
    "         label=\"CV accuracy\")\n",
    "plt.legend()\n",
    "plt.xlabel('Training size')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depths = np.arange(1,21,5)\n",
    "tree_lrn = DecisionTreeClassifier(criterion='gini')\n",
    "train_score, val_score = validation_curve(tree_lrn, X, y, param_name='max_depth', param_range=depths, cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Tree classifier vs. depth')\n",
    "plt.plot(depths, np.mean(val_score, 1), label='CV accuracy')\n",
    "plt.plot(depths, np.mean(train_score, 1), label='Training accuracy')\n",
    "plt.legend()\n",
    "plt.xlabel('Depth')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
